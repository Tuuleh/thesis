- instrument not 100% comparable to previous research
- unstandardised instruments
- only one game
- web-experiments (accuracy)
- server in San Francisco
- inadequate blinding, which might not be as severe as in VGP vs. NVGP studies, since everyone played video games and the population was hence more homogenic
- very self-selective sample
-'candy' between the experiments -> influence motivation (response was very positive)
- limited duration of individual tasks increases alpha error probability, but was necessary to keep participant number high

Due to the game:
- it was difficult to recruit from all the game regions
- decay: ratings vary also due to inactivity, not due to player performance; MMR: separate match maker rating for solo and team play
- the season was just about to come into end -> this could have been a good or a bad thing:
    - more active pvp players, but ratings might not be representative of the team's typical rating throughout the season
    - limited time for sampling


A few factors limit the scope of this study and should be discussed as its possible shortcomings.
Shortcomings regrding the instruments were that they were undstandardised and not absolutely comparable to those used in previous research. The cognitive tasks were composed as JavaScript-based web experiments, and as for now, there is very little research on how JavaScript-based solutions compare to laboratory experiments.



Andrews G., Murphy K. (2006). “Does video-game playing improve executive function?” in Frontiers in Cognitive Sciences, ed. Vanchevsky M. A., editor. (New York, NY: Nova Science Publishers, Inc.), 145–161 //this one is good for discussing shortcomings! FROM http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3171788/